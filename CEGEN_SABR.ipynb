{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d2c6be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 25 10:35:23 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  Off  | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    64W / 300W |  27523MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    335789      C   ...envs/stylegan2/bin/python    13051MiB |\n",
      "|    0   N/A  N/A   2719850      C   ...s/pytorch_cuda/bin/python     5171MiB |\n",
      "|    0   N/A  N/A   2946735      C   ...s/pytorch_cuda/bin/python     2327MiB |\n",
      "|    0   N/A  N/A   3597464      C   ...s/pytorch_cuda/bin/python     2737MiB |\n",
      "|    0   N/A  N/A   3968431      C   /usr/bin/python3.9               4223MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9737f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score\n",
    "import statistics as stat\n",
    "import statsmodels.distributions as smd\n",
    "import os\n",
    "\n",
    "ML = 100000 #nombre d'echantillons al√©atoire\n",
    "t_init = 0\n",
    "T  = 0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51b835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sabr_trajectory(alpha, beta, rho, f0, sigma0, T, dt, n_sim):\n",
    "    np.random.seed(42)\n",
    "    n_steps = int(T / dt)\n",
    "    \n",
    "    F = np.zeros((n_sim, n_steps + 1))\n",
    "    sigma = np.zeros((n_sim, n_steps + 1))\n",
    "    \n",
    "    F[:, 0] = f0\n",
    "    sigma[:, 0] = sigma0\n",
    "    \n",
    "    dW1 = np.sqrt(dt) * np.random.randn(n_sim, n_steps)\n",
    "    dW2 = rho * dW1 + np.sqrt(1 - rho**2) * np.sqrt(dt) * np.random.randn(n_sim, n_steps)\n",
    "    \n",
    "    for t in range(n_steps):\n",
    "        F[:, t+1] = F[:, t] + sigma[:, t] * F[:, t]**beta * dW1[:, t]\n",
    "        sigma[:, t+1] = sigma[:, t] + alpha * sigma[:, t] * dW2[:, t]\n",
    "    \n",
    "    return F, sigma\n",
    "\n",
    "# Function that saves different models during the training phase\n",
    "def save_network(network, epoch_label, minibatch):\n",
    "    save_filename = 'net_{}_{}.pth'.format(epoch_label , minibatch)\n",
    "    save_path = os.path.join('./SavedModels102', save_filename)\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "class Generator(torch.nn.Module):\n",
    "        def __init__(self, input_neurons, hidden_neurons, output_neurons ):\n",
    "            super(Generator, self).__init__()\n",
    "            self.hidden= nn.Linear(input_neurons, hidden_neurons)\n",
    "            self.hiddenM1= nn.Linear(hidden_neurons, hidden_neurons)\n",
    "            self.hiddenM2= nn.Linear(hidden_neurons, hidden_neurons)\n",
    "            #self.hiddenM3= nn.Linear(hidden_neurons, hidden_neurons)\n",
    "            self.Activ =torch.nn.Tanh()\n",
    "            #self.Activ =torch.nn.ReLU()\n",
    "\n",
    "            #self.Activ =torch.sin\n",
    "            self.eps = 1e-20\n",
    "            \n",
    "            self.bach1 = nn.BatchNorm1d(input_neurons)\n",
    "            self.bach2 = nn.BatchNorm1d(hidden_neurons)\n",
    "            self.bach3 = nn.BatchNorm1d(hidden_neurons)\n",
    "            self.bach4 = nn.BatchNorm1d(hidden_neurons)\n",
    "            self.bach5 = nn.BatchNorm1d(hidden_neurons)\n",
    "\n",
    "            self.out= nn.Linear(hidden_neurons, output_neurons)\n",
    "        def forward(self, x):\n",
    "            #x = self.bach1(x)\n",
    "            x = self.hidden(x)\n",
    "            x = self.Activ(x)\n",
    "            #x = self.bach2(x)           \n",
    "            x = self.hiddenM1(x)\n",
    "            x = self.Activ(x)\n",
    "            #x = self.bach3(x)           \n",
    "            x = self.hiddenM2(x)\n",
    "            x = self.Activ(x)\n",
    "            #x = self.bach4(x)           \n",
    "            #x = self.hiddenM3(x)            \n",
    "            #x = self.Activ(x)\n",
    "            #x = self.bach5(x)           \n",
    "            x = self.out(x)\n",
    "            \n",
    "            x[:,:-1] = torch.sigmoid(x[:,:-1])\n",
    "            #print(x[:,:-1])\n",
    "            x[:,-1] = torch.atan(x.clone()[:,-1])\n",
    "            #print(x[:,-1])\n",
    "            return x\n",
    "\n",
    "\n",
    "def Wass2Dim(Cc1, Cc2, X,Y, Nm, b):\n",
    "    Res=0\n",
    "    for k in range(Nm):\n",
    "        if k==0:\n",
    "            n01=0\n",
    "            n02=0\n",
    "            \n",
    "        else:\n",
    "            n01=n01+int(Cc1[k-1])\n",
    "            n02=n02+int(Cc2[k-1])\n",
    "       # if (n02==0):\n",
    "           # breakpoint()\n",
    "        n1=int(Cc1[k])\n",
    "        n2=int(Cc2[k])\n",
    "        #print(n01+n1)\n",
    "        #print(n02+n2)\n",
    "        McX=torch.zeros(1)\n",
    "        McY=torch.zeros(1)\n",
    "        VarX=torch.zeros(1)\n",
    "        VarY=torch.zeros(1)\n",
    "        epsilon=10**(-16)\n",
    "        Lambda=100000\n",
    "        if (n1 != 0) and (n2!= 0):\n",
    "            if (min(Y[n02:n02+n2,0,0]) <= max(X[n01:n01+n1,0,0])) and (max(Y[n02:n02+n2,0,0]) >= min(X[n01:n01+n1,0,0])):\n",
    "                if (n1!=1) and (n2!=1):\n",
    "                    #print('OUI')\n",
    "                    McX1=(1/n1)*torch.sum(X[n01:n01+n1,0,1])\n",
    "                    McX2=(1/n1)*torch.sum(X[n01:n01+n1,1,1])\n",
    "\n",
    "                    #VarX1=torch.var(X[n01:n01+n1,0])\n",
    "                    #VarX2=torch.var(X[n01:n01+n1,1])\n",
    "\n",
    "                    McY1=(1/n2)*torch.sum(Y[n02:n02+n2,0,1])\n",
    "                    McY2=(1/n2)*torch.sum(Y[n02:n02+n2,1,1])\n",
    "\n",
    "                    #VarY1=torch.var(Y[n02:n02+n2,0])\n",
    "                    #VarY2=torch.var(Y[n02:n02+n2,1])\n",
    "                    \n",
    "                    #breakpoint()\n",
    "                    CovX=torch.cov(X[n01:n01+n1,:,1].T)\n",
    "                    CX=torch.linalg.eig(CovX)\n",
    "                    \n",
    "                    CEig=torch.view_as_real(CX[0])\n",
    "                    S=torch.view_as_real(CX[1])\n",
    "                    Si=torch.zeros(2,2)\n",
    "                    Si[:,0]=S[:,0][:,0]\n",
    "                    Si[:,1]=S[:,1][:,0]\n",
    "                    #breakpoint()\n",
    "                    #SqCovX=torch.transpose(Si, 0, 1).mm(torch.diag((CEig[:,0])**(1/2))).mm(Si)\n",
    "                    SqCovX=Si.mm(torch.diag((CEig[:,0])**(1/2))).mm(torch.transpose(Si, 0, 1))\n",
    "                    CovY=torch.cov(Y[n02:n02+n2,:,1].T)\n",
    "                    \n",
    "                    S14=(SqCovX.mm(CovY)).mm(SqCovX)\n",
    "                    C2X=torch.linalg.eig(S14)\n",
    "                    C2Eig=torch.view_as_real(C2X[0])\n",
    "                    S2=torch.view_as_real(C2X[1])\n",
    "                    S2i=torch.zeros(2,2)\n",
    "                    S2i[:,0]=S2[:,0][:,0]\n",
    "                    S2i[:,1]=S2[:,1][:,0]\n",
    "                    #breakpoint()\n",
    "                    #SqCovX=torch.transpose(Si, 0, 1).mm(torch.diag((CEig[:,0])**(1/2))).mm(Si)\n",
    "                    Sq4=S2i.mm(torch.diag((C2Eig[:,0])**(1/2))).mm(torch.transpose(S2i, 0, 1))\n",
    "\n",
    "\n",
    "                    #breakpoint()\n",
    "                    if k==0:\n",
    "                        if (CovX[0,0] > epsilon) and (CovY[0,0] > epsilon):\n",
    "                            #B=torch.trace(CovX)+torch.trace(CovY)-2*torch.sqrt(torch.trace((SqCovX.mm(CovY)).mm(SqCovX)))\n",
    "                            B=torch.trace(CovX)+torch.trace(CovY)-2*torch.trace(Sq4)\n",
    "\n",
    "                            Res=(McX1-McY1)**2+(McX2-McY2)**2+B\n",
    "                        else :\n",
    "                            print('Yes1')\n",
    "                           #Res=(McX-McY)**2+VarX+VarY-2*torch.sqrt(VarX*VarY+epsilon)\n",
    "                           #Res=(McX-McY)**2+VarX+VarY\n",
    "                            Res=Lambda*(abs(McX1-McY1)+abs(McX2-McY2))\n",
    "                    else:\n",
    "                        #print(CovX[0,0])\n",
    "                        if (CovX[0,0] > epsilon) and (CovY[0,0]  > epsilon):\n",
    "                            #B=torch.trace(CovX)+torch.trace(CovY)-2*torch.sqrt(torch.trace((SqCovX.mm(CovY)).mm(SqCovX)))\n",
    "                            B=torch.trace(CovX)+torch.trace(CovY)-2*torch.trace(Sq4)\n",
    "                            Res=Res+(McX1-McY1)**2+(McX2-McY2)**2+B\n",
    "                            #Res=Res+(McX-McY)**2\n",
    "                        else :\n",
    "                            print('Yes1')\n",
    "                            #Res=Res+(McX-McY)**2+VarX+VarY-2*torch.sqrt(VarX*VarY+epsilon)\n",
    "                            #Res=Res+(McX-McY)**2+VarX+VarY\n",
    "                            Res=Res+Lambda*(abs(McX1-McY1)+abs(McX2-McY2))\n",
    "                else:\n",
    "                    if (n1==1) and (int(n01+n1)==int(b)):\n",
    "                        #print('yes2')\n",
    "                        McX=(1/n1)*X[n01]\n",
    "                        VarX=torch.zeros(1)  \n",
    "                    else:\n",
    "                        #print('yes3')\n",
    "                        McX=X[n01+n1]\n",
    "                        VarX=torch.zeros(1)        \n",
    "                    \n",
    "                    #print(n01+n1)\n",
    "                    #print(n02+n2)\n",
    "                    if (n2!=1):\n",
    "                        #print('yes1')\n",
    "                        McY=(1/n2)*torch.sum(Y[n02:n02+n2])\n",
    "                        VarY=torch.var(Y[n02:n02+n2])\n",
    "                        \n",
    "                    elif (n2==1) and (int(n02+n2)==int(b)):\n",
    "                        #print('yes2')\n",
    "                        McY=(1/n2)*Y[n02]\n",
    "                        VarY=torch.zeros(1)  \n",
    "                        #breakpoint()\n",
    "                    else:\n",
    "                        #print('yes3')\n",
    "                        McY=Y[n02+n2]\n",
    "                        VarY=torch.zeros(1)   \n",
    "                        #breakpoint()\n",
    "                    if k==0:\n",
    "                        print('Yes2')\n",
    "                        Res=Lambda*abs(McX-McY)\n",
    "                    else:\n",
    "                        print('Yes2')\n",
    "                        Res=Res+Lambda*abs(McX-McY)\n",
    "\n",
    "    return Res      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Wass2DimY(Cc1, Cc2, X,Y, Nm, b):\n",
    "    Res=0\n",
    "    for k in range(Nm):\n",
    "        if k==0:\n",
    "            n01=0\n",
    "            n02=0\n",
    "            \n",
    "        else:\n",
    "            n01=n01+int(Cc1[k-1])\n",
    "            n02=n02+int(Cc2[k-1])\n",
    "       # if (n02==0):\n",
    "           # breakpoint()\n",
    "        n1=int(Cc1[k])\n",
    "        n2=int(Cc2[k])\n",
    "        #print(n01+n1)\n",
    "        #print(n02+n2)\n",
    "        McX=torch.zeros(1)\n",
    "        McY=torch.zeros(1)\n",
    "        VarX=torch.zeros(1)\n",
    "        VarY=torch.zeros(1)\n",
    "        epsilon=10**(-16)\n",
    "        Lambda=100000\n",
    "        if (n1 != 0) and (n2!= 0):\n",
    "            if (min(Y[n02:n02+n2,0,0]) <= max(X[n01:n01+n1,0,0])) and (max(Y[n02:n02+n2,0,0]) >= min(X[n01:n01+n1,0,0])):\n",
    "                if (n1!=1) and (n2!=1):\n",
    "                    #print('OUI')\n",
    "                    McX1=(1/n1)*torch.sum(X[n01:n01+n1,0,1])\n",
    "                    McX2=(1/n1)*torch.sum(X[n01:n01+n1,1,1])\n",
    "\n",
    "                    #VarX1=torch.var(X[n01:n01+n1,0])\n",
    "                    #VarX2=torch.var(X[n01:n01+n1,1])\n",
    "\n",
    "                    McY1=(1/n2)*torch.sum(Y[n02:n02+n2,0,1])\n",
    "                    McY2=(1/n2)*torch.sum(Y[n02:n02+n2,1,1])\n",
    "\n",
    "                    #VarY1=torch.var(Y[n02:n02+n2,0])\n",
    "                    #VarY2=torch.var(Y[n02:n02+n2,1])\n",
    "                    \n",
    "                    #breakpoint()\n",
    "                    CovY=torch.cov(Y[n02:n02+n2,:,1].T)\n",
    "                    CY=torch.linalg.eig(CovY)\n",
    "                    \n",
    "                    CEig=torch.view_as_real(CY[0])\n",
    "                    S=torch.view_as_real(CY[1])\n",
    "                    Si=torch.zeros(2,2)\n",
    "                    Si[:,0]=S[:,0][:,0]\n",
    "                    Si[:,1]=S[:,1][:,0]\n",
    "                    #breakpoint()\n",
    "                    #SqCovX=torch.transpose(Si, 0, 1).mm(torch.diag((CEig[:,0])**(1/2))).mm(Si)\n",
    "                    SqCovY=Si.mm(torch.diag((CEig[:,0])**(1/2))).mm(torch.transpose(Si, 0, 1))\n",
    "                    CovX=torch.cov(X[n01:n01+n1,:,1].T)\n",
    "                    #breakpoint()\n",
    "                    if k==0:\n",
    "                        if (CovX[0,0] > epsilon) and (CovY[0,0] > epsilon):\n",
    "                            B=torch.trace(CovX)+torch.trace(CovY)-2*torch.sqrt(torch.trace((SqCovY.mm(CovX)).mm(SqCovY)))\n",
    "                            Res=(McX1-McY1)**2+(McX2-McY2)**2+B\n",
    "                        else :\n",
    "                            print('Yes1')\n",
    "                           #Res=(McX-McY)**2+VarX+VarY-2*torch.sqrt(VarX*VarY+epsilon)\n",
    "                           #Res=(McX-McY)**2+VarX+VarY\n",
    "                            Res=Lambda*(abs(McX1-McY1)+abs(McX2-McY2))\n",
    "                    else:\n",
    "                        #print(CovX[0,0])\n",
    "                        if (CovX[0,0] > epsilon) and (CovY[0,0]  > epsilon):\n",
    "                            #print('Yes1')\n",
    "                            B=torch.trace(CovX)+torch.trace(CovY)-2*torch.sqrt(torch.trace((SqCovY.mm(CovX)).mm(SqCovY)))\n",
    "                            Res=Res+(McX1-McY1)**2+(McX2-McY2)**2+B\n",
    "                            #Res=Res+(McX-McY)**2\n",
    "                        else :\n",
    "                            print('Yes1')\n",
    "                            #Res=Res+(McX-McY)**2+VarX+VarY-2*torch.sqrt(VarX*VarY+epsilon)\n",
    "                            #Res=Res+(McX-McY)**2+VarX+VarY\n",
    "                            Res=Res+Lambda*(abs(McX1-McY1)+abs(McX2-McY2))\n",
    "                else:\n",
    "                    if (n1==1) and (int(n01+n1)==int(b)):\n",
    "                        #print('yes2')\n",
    "                        McX=(1/n1)*X[n01]\n",
    "                        VarX=torch.zeros(1)  \n",
    "                    else:\n",
    "                        #print('yes3')\n",
    "                        McX=X[n01+n1]\n",
    "                        VarX=torch.zeros(1)        \n",
    "                    \n",
    "                    #print(n01+n1)\n",
    "                    #print(n02+n2)\n",
    "                    if (n2!=1):\n",
    "                        #print('yes1')\n",
    "                        McY=(1/n2)*torch.sum(Y[n02:n02+n2])\n",
    "                        VarY=torch.var(Y[n02:n02+n2])\n",
    "                        \n",
    "                    elif (n2==1) and (int(n02+n2)==int(b)):\n",
    "                        #print('yes2')\n",
    "                        McY=(1/n2)*Y[n02]\n",
    "                        VarY=torch.zeros(1)  \n",
    "                        #breakpoint()\n",
    "                    else:\n",
    "                        #print('yes3')\n",
    "                        McY=Y[n02+n2]\n",
    "                        VarY=torch.zeros(1)   \n",
    "                        #breakpoint()\n",
    "                    if k==0:\n",
    "                        print('Yes2')\n",
    "                        Res=Lambda*abs(McX-McY)\n",
    "                    else:\n",
    "                        print('Yes2')\n",
    "                        Res=Res+Lambda*abs(McX-McY)\n",
    "\n",
    "    return Res  \n",
    "\n",
    "def PartitionQuantilesVect(V, Nm, b, d):\n",
    "    '''\n",
    "    if ((l%2)==0):\n",
    "        d=0\n",
    "        #print('I1')\n",
    "    else:\n",
    "        #print('I2')\n",
    "        d=1\n",
    "    '''\n",
    "    Qk=stat.quantiles((V[:,d,0]).detach(),n=Nm)\n",
    "    Ik=torch.zeros(Nm+1)\n",
    "    Ik[0]=min(V[:,d,0])\n",
    "    \n",
    "    Ik[Nm]=max(V[:,d,0])\n",
    "    for l in range(0,Nm-1):\n",
    "        Ik[l+1]=Qk[l]\n",
    "    \n",
    "    f=0\n",
    "    T=torch.zeros(b,2,3);\n",
    "    i=0\n",
    "    Cc=torch.zeros(Nm)\n",
    "\n",
    "    for p in range(Nm):\n",
    "        s=0\n",
    "        for l in range(b):\n",
    "            if (Ik[p] < V[l,d,0]) and (V[l,d,0]<= Ik[p+1] ):\n",
    "                T[f,0,:-1]=V[l,0,:]\n",
    "                T[f,1,:-1]=V[l,1,:]\n",
    "                f=f+1\n",
    "                s=s+1             \n",
    "                #print('f=',f,'l=',l,'p=',p)\n",
    "        if s!= 0:\n",
    "            T[f-1,-1:]=int(s)\n",
    "            Cc[i]=int(s)\n",
    "            i=i+1\n",
    "        #if Cc[0]==0:\n",
    "            #breakpoint()\n",
    "    return (T, Cc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a987a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''*********************Data set*********************'''\n",
    "\n",
    "# Data set for the SABR model\n",
    "\n",
    "alpha = 0.2\n",
    "beta = 0.8\n",
    "rho = -0.3\n",
    "f0 = 100\n",
    "sigma0 = 0.36\n",
    "ML = 10000\n",
    "\n",
    "F_fine, sigma_fine = sabr_trajectory(alpha, beta, rho, f0, sigma0, T, dt1, ML)\n",
    "\n",
    "StNumML1=np.zeros((ML, 2, ts1.size+1), dtype=np.float32) #Matrix of the input data \n",
    "StNumML1[:,0,:]=F_fine\n",
    "StNumML1[:,1,:]=sigma_fine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45c9055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Networks'''\n",
    "\n",
    "#Generator Network\n",
    "NetworkG = Generator(input_neurons = 2, hidden_neurons = 16, output_neurons = 3)\n",
    "\n",
    "'''Optimizers'''\n",
    "\n",
    "#Generator optimizer Network\n",
    "optimizerG = torch.optim.Adam(NetworkG.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93fc3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batche_size=300\n",
    "\n",
    "Ntrain=ML  #Size of the training set\n",
    "NetworkG.train()\n",
    "LossMSE=nn.MSELoss()\n",
    "\n",
    "'''Partition'''\n",
    "\n",
    "for epoch in range(100):\n",
    "    for mini_batches in range(int(Ntrain/batche_size)):\n",
    "            #mini_batches=0\n",
    "            Nm=2\n",
    "            Xtrain=torch.as_tensor(StNumML1[mini_batches*batche_size:(mini_batches+1)*batche_size,:,:])\n",
    "            lik=0\n",
    "            Ypi=torch.empty(batche_size,2)\n",
    "            Ypp=torch.zeros(batche_size,2)\n",
    "            Ypi[:,:]=Xtrain[:,:,1]\n",
    "            l=0\n",
    "            for j in range(1,ts1.size):\n",
    "                YTorch=Xtrain[:,:,j:j+2]\n",
    "                #Y, CcY=PartitionQuantilesVect(YTorch, Nm, batche_size, l)\n",
    "                '''\n",
    "                if (j!=1):\n",
    "                    YpiTorch[:,0]=Ypp.detach()\n",
    "                '''\n",
    "                ParaG=NetworkG(Ypi)\n",
    "                #print('ParaG=',ParaG)\n",
    "                galpha=ParaG[:,0]\n",
    "                gbeta=ParaG[:,1]\n",
    "                grho=ParaG[:,2]\n",
    "                torch.random.seed()\n",
    "                dW   = torch.normal(0,1,size=(1, 2*batche_size))\n",
    "                dW21 = dW[0,:batche_size]\n",
    "                dW31 = grho*dW21+torch.sqrt(1 - grho**2) *dW[0,batche_size:]\n",
    "                \n",
    "                Ypp[:,0]=Ypi[:,0]+Ypi[:,1]*(Ypi[:,0]**gbeta)*(dt1**(1/2))*dW21[:]\n",
    "                Ypp[:,1]=Ypi[:,1]+(galpha)*Ypi[:,1]*(dt1**(1/2))*dW31[:]\n",
    "                \n",
    "                Ypi=(Ypp).clone()\n",
    "                YpT=torch.empty(batche_size,2,2)\n",
    "                YpT[:,0,:]=torch.cat(( Ypi[:,0].view(-1,1), (Ypp[:,0]).view(-1,1)), dim=1)\n",
    "                YpT[:,1,:]=torch.cat(( Ypi[:,1].view(-1,1), (Ypp[:,1]).view(-1,1)), dim=1)\n",
    "\n",
    "                for d in range(2):\n",
    "                    Y, CcY=PartitionQuantilesVect(YTorch, Nm, batche_size, d)\n",
    "                    Yp, CcYp=PartitionQuantilesVect(YpT, Nm, batche_size, d)\n",
    "                    \n",
    "                    if (j==1):\n",
    "                            lik=lik+Wass2Dim(CcY, CcYp, Y[:,:,:], (Yp[:,:,:]), Nm, batche_size)\n",
    "                           # breakpoint()\n",
    "                    else:\n",
    "                            lik=lik.clone()+Wass2Dim(CcY, CcYp, Y[:,:,:], (Yp[:,:,:]), Nm, batche_size)  \n",
    "                            #lik=Wass2Dim(CcY, CcYp, Y[:,:,:], (Yp[:,:,:]), Nm, batche_size)  \n",
    "                #breakpoint()\n",
    "                #Generator_loss=torch.sum(Ypp)\n",
    "                #print('lik=',lik)\n",
    "                \n",
    "                #lik=Wass2(CcY, CcYp, Y[:,1], (Yp[:,1]), Nm, batche_size) \n",
    "                #lik=LossMSE(Ypp[:,0], YTorch[:,0])\n",
    "                #breakpoint()\n",
    "                \n",
    "                '''\n",
    "                Generator_loss= lik\n",
    "                optimizerG.zero_grad()\n",
    "                Generator_loss.backward(retain_graph=True)\n",
    "                #print('grad=',Generator_loss.grad)  \n",
    "                #Genrator network parameters update\n",
    "                optimizerG.step()\n",
    "                \n",
    "                \n",
    "                #print(Generator_loss)\n",
    "                #Genrator network optimizer to initialize\n",
    "                #breakpoint()\n",
    "                #print(lik)\n",
    "                print('ParaG=',ParaG)\n",
    "                print('j=',j)\n",
    "                #print('lik=',lik)\n",
    "                print('grad=', Generator_loss)    \n",
    "                print('epoch=', epoch)\n",
    "                \n",
    "                #YpiTorch[:,0]=Ypp.clone() \n",
    "                '''\n",
    "            #print('MeanSigB=',torch.mean(ParaG[:,1]/Ypi[:,0]))\n",
    "            #print('MeanDriftB=',torch.mean(ParaG[:,0]/Ypi[:,0]))\n",
    "            Generator_loss = lik\n",
    "            optimizerG.zero_grad()\n",
    "            #Genrator network backpropagation\n",
    "            Generator_loss.backward(retain_graph=True)\n",
    "            #Genrator network parameters update\n",
    "            optimizerG.step()\n",
    "            #print('ParaG=',ParaG)\n",
    "            print('epoch=', epoch)\n",
    "            print('Error Generator=', Generator_loss/(Nm*d*N1))\n",
    "            #print('MeanSigA=',torch.mean(ParaG[:,1]/Ypi[:,0]))\n",
    "            #print('MeanDriftA=',torch.mean(ParaG[:,0]/Ypi[:,0]))\n",
    "            print('MeanBeta=',torch.mean(ParaG[:,1]))\n",
    "            print('MeanAlpha=',torch.mean(ParaG[:,0]))\n",
    "            print('grho=',torch.mean(ParaG[:,2]))\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            #breakpoint()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86706e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
